{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "17262c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "\n",
    "class SfMCalibrator:\n",
    "    def __init__(self, max_iter=100, reproj_thresh=2.0, pyr_levels=2):\n",
    "        self.max_iter = max_iter\n",
    "        self.reproj_thresh = reproj_thresh\n",
    "        self.images = []\n",
    "        self.K = None\n",
    "        self.dist_coeffs = np.zeros(5, dtype=np.float64)  # ✅ 수정됨\n",
    "        self.rotations = []\n",
    "        self.translations = []\n",
    "        self.image_size = None\n",
    "        self.pyr_levels = pyr_levels\n",
    "\n",
    "    def __call__(self, image_list):\n",
    "        self.set_images(image_list)\n",
    "        return self.run_pipeline()\n",
    "\n",
    "    def set_images(self, image_list):\n",
    "        self.images = [img.copy() for img in image_list if img is not None]\n",
    "        if not self.images:\n",
    "            raise ValueError(\"No valid images\")\n",
    "        self._init_camera_params()\n",
    "\n",
    "    def _init_camera_params(self):\n",
    "        h, w = self.images[0].shape[:2]\n",
    "        self.image_size = (w, h)\n",
    "        gray = cv2.cvtColor(self.images[0], cv2.COLOR_BGR2GRAY)\n",
    "        initial_f = self.image_size[0]\n",
    "        self.K = np.array([[initial_f, 0, w/2],\n",
    "                           [0, initial_f, h/2],\n",
    "                           [0, 0, 1]], dtype=np.float64)\n",
    "        self.rotations = [np.eye(3, dtype=np.float64)]\n",
    "        self.translations = [np.zeros((3, 1), dtype=np.float64)]\n",
    "\n",
    "    def _extract_features(self):\n",
    "        sift = cv2.SIFT_create()\n",
    "        features = []\n",
    "        for img in self.images:\n",
    "            pyr = [img]\n",
    "            for _ in range(self.pyr_levels):\n",
    "                pyr.append(cv2.pyrDown(pyr[-1]))\n",
    "            kp, des = [], []\n",
    "            for p_img in pyr:\n",
    "                gray = cv2.cvtColor(p_img, cv2.COLOR_BGR2GRAY)\n",
    "                k, d = sift.detectAndCompute(gray, None)\n",
    "                if k:\n",
    "                    scale = img.shape[1] / p_img.shape[1]\n",
    "                    k = [cv2.KeyPoint(x.pt[0]*scale, x.pt[1]*scale, x.size*scale, \n",
    "                                     x.angle, x.response, x.octave, x.class_id) for x in k]\n",
    "                    kp.extend(k)\n",
    "                    des.append(d) if d is not None else None\n",
    "            des = np.vstack(des) if des else None\n",
    "            features.append((kp, des))\n",
    "        return features\n",
    "\n",
    "    def _match_features(self, features):\n",
    "        matcher = cv2.BFMatcher()\n",
    "        matches = []\n",
    "        n = len(features)\n",
    "        for i in range(n-1):\n",
    "            kp1, des1 = features[i]\n",
    "            kp2, des2 = features[i+1]\n",
    "            if des1 is None or des2 is None:\n",
    "                continue\n",
    "\n",
    "            # 변경된 부분: OpenCV의 knnMatch 사용\n",
    "            raw_matches = matcher.knnMatch(des1, des2, k=2)\n",
    "            good = []\n",
    "            for m, n in raw_matches:\n",
    "                if m.distance < 0.65 * n.distance:\n",
    "                    good.append(m)\n",
    "\n",
    "            matches.append((i, i+1, kp1, kp2, good))\n",
    "        return matches\n",
    "\n",
    "\n",
    "    def _undistort_points(self, pts):\n",
    "        pts = np.asarray(pts, dtype=np.float32).reshape(-1, 1, 2)\n",
    "        return cv2.undistortPoints(pts, self.K, self.dist_coeffs).reshape(-1, 2)  # ✅ P=None (default)\n",
    "\n",
    "\n",
    "    def _estimate_pose(self, kp1, kp2, matches):\n",
    "        pts1 = np.float32([kp1[m.queryIdx].pt for m in matches])\n",
    "        pts2 = np.float32([kp2[m.trainIdx].pt for m in matches])\n",
    "        pts1u = self._undistort_points(pts1)\n",
    "        pts2u = self._undistort_points(pts2)\n",
    "        E, mask = cv2.findEssentialMat(pts1u, pts2u, self.K, cv2.RANSAC, 0.999, self.reproj_thresh)\n",
    "        _, R, t, _ = cv2.recoverPose(E, pts1u, pts2u, self.K, mask=mask)\n",
    "        return R, t, mask\n",
    "\n",
    "    def _triangulate(self, R, t, kp1, kp2, matches, mask):\n",
    "        P1 = self.K @ np.hstack([np.eye(3), np.zeros((3,1))])\n",
    "        P2 = self.K @ np.hstack([R, t])\n",
    "        mask = mask.ravel().astype(bool)\n",
    "        pts1 = np.float32([kp1[m.queryIdx].pt for m in matches])[mask]\n",
    "        pts2 = np.float32([kp2[m.trainIdx].pt for m in matches])[mask]\n",
    "        pts4d = cv2.triangulatePoints(P1, P2, pts1.T, pts2.T)\n",
    "        return (pts4d[:3]/pts4d[3]).T\n",
    "\n",
    "    def _lm_optimize(self, params, points_3d, points_2d, camera_indices):\n",
    "        x = params.astype(np.float64)\n",
    "        lambda_ = 1e-2\n",
    "        for _ in range(self.max_iter):\n",
    "            residuals = self._compute_residuals(x, points_3d, points_2d, camera_indices)\n",
    "            J = self._compute_jacobian(x, points_3d, points_2d, camera_indices)\n",
    "            grad = J.T @ residuals\n",
    "            hess = J.T @ J\n",
    "            delta = np.linalg.solve(hess + lambda_*np.eye(len(x)), -grad)\n",
    "            x_new = x + delta\n",
    "            new_residuals = self._compute_residuals(x_new, points_3d, points_2d, camera_indices)\n",
    "            if np.linalg.norm(new_residuals) < np.linalg.norm(residuals):\n",
    "                x = x_new\n",
    "                lambda_ *= 0.1\n",
    "            else:\n",
    "                lambda_ *= 10\n",
    "        return x\n",
    "\n",
    "    def _compute_residuals(self, params, points_3d, points_2d, camera_indices):\n",
    "        f, k1, k2 = params\n",
    "        cx, cy = self.image_size[0] / 2, self.image_size[1] / 2\n",
    "        K = np.array([[f, 0, cx],\n",
    "                    [0, f, cy],\n",
    "                    [0, 0, 1]])\n",
    "\n",
    "        residuals = []\n",
    "        for i, (pt3d, pt2d) in enumerate(zip(points_3d, points_2d)):\n",
    "            R = self.rotations[camera_indices[i]]\n",
    "            t = self.translations[camera_indices[i]]\n",
    "            proj = K @ (R @ pt3d.reshape(3, 1) + t)\n",
    "            z = proj[2, 0]\n",
    "\n",
    "            if z <= 1e-6:\n",
    "                residuals.extend([0.0, 0.0])\n",
    "                continue\n",
    "\n",
    "            proj = proj[:2, 0] / z\n",
    "            x = proj[0] - cx\n",
    "            y = proj[1] - cy\n",
    "            r2 = x ** 2 + y ** 2\n",
    "            proj = proj * (1 + k1 * r2 + k2 * r2 ** 2) + np.array([cx, cy])\n",
    "            residuals.extend(proj - pt2d)\n",
    "\n",
    "        return np.array(residuals)\n",
    "\n",
    "\n",
    "\n",
    "    def _compute_jacobian(self, params, points_3d, points_2d, camera_indices, eps=1e-6):\n",
    "        n_params = len(params)\n",
    "        base = self._compute_residuals(params, points_3d, points_2d, camera_indices)\n",
    "        J = np.zeros((len(base), n_params))\n",
    "\n",
    "        for i in range(n_params):\n",
    "            perturbed = params.copy()\n",
    "            perturbed[i] += eps\n",
    "            delta = self._compute_residuals(perturbed, points_3d, points_2d, camera_indices)\n",
    "\n",
    "            if delta.shape == base.shape:\n",
    "                J[:, i] = (delta - base) / eps\n",
    "            else:\n",
    "                raise ValueError(f\"Jacobian shape mismatch: {delta.shape} vs {base.shape}\")\n",
    "\n",
    "        return J\n",
    "\n",
    "\n",
    "\n",
    "    def run_pipeline(self):\n",
    "        features = self._extract_features()\n",
    "        matches = self._match_features(features)\n",
    "        points_3d, points_2d, indices = [], [], []\n",
    "\n",
    "        for i, j, kp1, kp2, ms in matches:\n",
    "            if len(ms) < 4:\n",
    "                continue\n",
    "            R, t, mask = self._estimate_pose(kp1, kp2, ms)\n",
    "            pts3d = self._triangulate(R, t, kp1, kp2, ms, mask)\n",
    "            if len(pts3d) == 0:\n",
    "                continue\n",
    "            inliers = np.where(mask.ravel() == 1)[0]\n",
    "            points_3d.append(pts3d)\n",
    "            points_2d.extend([kp1[ms[i].queryIdx].pt for i in inliers])\n",
    "            indices.extend([i] * len(inliers))\n",
    "            if len(self.rotations) <= j:\n",
    "                self.rotations.append(R @ self.rotations[i])\n",
    "                self.translations.append(self.translations[i] + t)\n",
    "\n",
    "        all_points_3d = np.vstack(points_3d)\n",
    "        all_points_2d = np.array(points_2d)\n",
    "        camera_indices = np.array(indices)\n",
    "\n",
    "        # 깊이 마스킹\n",
    "        valid_mask = all_points_3d[:, 2] > 1e-6\n",
    "        all_points_3d = all_points_3d[valid_mask]\n",
    "        all_points_2d = all_points_2d[valid_mask]\n",
    "        camera_indices = camera_indices[valid_mask]\n",
    "\n",
    "        # ✅ cx, cy 고정하고 f, k1, k2만 추정\n",
    "        params = np.array([self.K[0, 0], 0, 0])  # f, k1, k2\n",
    "        params = self._lm_optimize(params, all_points_3d, all_points_2d, camera_indices)\n",
    "\n",
    "        # ✅ 최종 intrinsic matrix 구성\n",
    "        cx, cy = self.image_size[0] / 2, self.image_size[1] / 2\n",
    "        self.K = np.array([[params[0], 0, cx],\n",
    "                        [0, params[0], cy],\n",
    "                        [0, 0, 1]])\n",
    "        self.dist_coeffs = np.array(params[1:3])\n",
    "        return self.K, self.dist_coeffs, self.rotations\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b690a01d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1329, 2000, 3)\n"
     ]
    }
   ],
   "source": [
    "print(img1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1d85446c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img1 = cv2.imread('./image/problem_2/3.jpg')\n",
    "# img2 = cv2.imread('./image/problem_2/4.jpg')\n",
    "# img3 = cv2.imread('./image/problem_2/5.jpg')\n",
    "# img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
    "# img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
    "# img3 = cv2.cvtColor(img3, cv2.COLOR_BGR2RGB)\n",
    "# image_list = [img1, img2, img3]\n",
    "# calibration = SfMCalibrator()\n",
    "# K, dist_coeffs, rotations = calibration(image_list)\n",
    "# print(\"Intrinsic Matrix (K):\", K)\n",
    "# print(\"Distortion Coefficients:\", dist_coeffs)\n",
    "# print(\"Rotations:\", rotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc39df89",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread('./image/problem_3/1.jpg')\n",
    "img2 = cv2.imread('./image/problem_3/2.jpg')\n",
    "img3 = cv2.imread('./image/problem_3/3.jpg')\n",
    "img4 = cv2.imread('./image/problem_3/4.jpg')\n",
    "img5 = cv2.imread('./image/problem_3/5.jpg')\n",
    "img6 = cv2.imread('./image/problem_3/6.jpg')\n",
    "img7 = cv2.imread('./image/problem_3/7.jpg')\n",
    "img8 = cv2.imread('./image/problem_3/8.jpg')\n",
    "img9 = cv2.imread('./image/problem_3/9.jpg')\n",
    "img10 = cv2.imread('./image/problem_3/10.jpg')\n",
    "img11 = cv2.imread('./image/problem_3/11.jpg')\n",
    "img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
    "img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
    "img3 = cv2.cvtColor(img3, cv2.COLOR_BGR2RGB)\n",
    "img4 = cv2.cvtColor(img4, cv2.COLOR_BGR2RGB)\n",
    "img5 = cv2.cvtColor(img5, cv2.COLOR_BGR2RGB)\n",
    "img6 = cv2.cvtColor(img6, cv2.COLOR_BGR2RGB)\n",
    "img7 = cv2.cvtColor(img7, cv2.COLOR_BGR2RGB)\n",
    "img8 = cv2.cvtColor(img8, cv2.COLOR_BGR2RGB)\n",
    "img9 = cv2.cvtColor(img9, cv2.COLOR_BGR2RGB)\n",
    "img10 = cv2.cvtColor(img10, cv2.COLOR_BGR2RGB)\n",
    "img11 = cv2.cvtColor(img11, cv2.COLOR_BGR2RGB)\n",
    "image_list = [img1, img2, img3, img4, img5, img6, img7, img8, img9, img10, img11]\n",
    "calibration = SfMCalibrator()\n",
    "K, dist_coeffs, rotations = calibration(image_list)\n",
    "print(\"Intrinsic Matrix (K):\", K)\n",
    "print(\"Distortion Coefficients:\", dist_coeffs)\n",
    "print(\"Rotations:\", rotations)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
